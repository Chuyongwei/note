{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aef1c7-8c58-488a-bff9-ede3659922fa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| W的维度              | b的维度              | 激活值的计算                          | 激活值的维度                          |\n",
    "| -------------------- | -------------------- | ------------------------------------- | ------------------------------------- |\n",
    "| $(n^{[1]},12288)$    | $(n^{[1]},1)$        | $(n^{[1]},1)$                         | $(n^{[1]},1)$                         |\n",
    "| $(n^{[2]}, n^{[1]})$ | $(n^{[2]}, n^{[1]})$ | $Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$ | $Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$ |\n",
    "| $\\vdots$             | $\\vdots$             | $\\vdots$                              | $\\vdots$                              |\n",
    "\n",
    "\n",
    "\n",
    "第 L-1 层 \n",
    "\n",
    " $(n^{[L-1]}, n^{[L-2]})$ \n",
    "\n",
    " $Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]}$\n",
    "\n",
    " $(n^{[L-1]}, 209)$ \n",
    "\n",
    "第 L 层 \n",
    "\n",
    "$(n^{[L]}, n^{[L-1]})$ \n",
    "\n",
    "$(n^{[L]}, 1)$\n",
    "\n",
    " $Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]}$ \n",
    "\n",
    "$(n^{[L]}, 209)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae48e9e-e4d8-4aa5-961d-535c745fc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import testCases #参见资料包，或者在文章底部copy\n",
    "from dnn_utils import sigmoid, sigmoid_backward, relu, relu_backward #参见资料包\n",
    "import lr_utils #参见资料包，或者在文章底部copy\n",
    "\n",
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    \"\"\"\n",
    "    此函数是为了初始化两层网络参数而使用的函数。\n",
    "    参数：\n",
    "        n_x - 输入层节点数量\n",
    "        n_h - 隐藏层节点数量\n",
    "        n_y - 输出层节点数量\n",
    "    \n",
    "    返回：\n",
    "        parameters - 包含你的参数的python字典：\n",
    "            W1 - 权重矩阵,维度为（n_h，n_x）\n",
    "            b1 - 偏向量，维度为（n_h，1）\n",
    "            W2 - 权重矩阵，维度为（n_y，n_h）\n",
    "            b2 - 偏向量，维度为（n_y，1）\n",
    "\n",
    "    \"\"\"\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    #使用断言确保我的数据格式是正确的\n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8393e5b-e008-46ec-b2d5-50707784349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============测试initialize_parameters==============\n",
      "W1 = [[-0.01380943  0.00385423  0.00127259]\n",
      " [ 0.00193025 -0.01099244  0.00542394]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.00210618 -0.00742477]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==============测试initialize_parameters==============\")\n",
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b8ba81-d67a-4210-88c4-5d5920cb573f",
   "metadata": {},
   "source": [
    "$(n^{[L-1]}, n^{[L-2]})$ $(n^{[L-1]}, 1)$ $Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]}$ $(n^{[L-1]}, 209)$ \n",
    "\n",
    "第 L 层\n",
    "\n",
    "$(n^{[L]}, n^{[L-1]})$ $(n^{[L]}, 1)$ $Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]}$ $(n^{[L]}, 209)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7918221-2dab-4e90-95ea-ecf80183c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers_dims):\n",
    "    \"\"\"\n",
    "    此函数是为了初始化多层网络参数而使用的函数。\n",
    "    参数：\n",
    "        layers_dims - 包含我们网络中每个图层的节点数量的列表\n",
    "    \n",
    "    返回：\n",
    "        parameters - 包含参数“W1”，“b1”，...，“WL”，“bL”的字典：\n",
    "                     W1 - 权重矩阵，维度为（layers_dims [1]，layers_dims [1-1]）\n",
    "                     bl - 偏向量，维度为（layers_dims [1]，1）\n",
    "    \"\"\"\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) / np.sqrt(layers_dims[l - 1])   \n",
    "        parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "        \n",
    "        #确保我要的数据的格式是正确的\n",
    "        assert(parameters[\"W\" + str(l)].shape == (layers_dims[l], layers_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layers_dims[l], 1))\n",
    "        \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5ac553-cffb-4f16-95b1-d336010b4e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============测试initialize_parameters_deep==============\n",
      "W1 = [[ 0.79989897  0.19521314  0.04315498 -0.83337927 -0.12405178]\n",
      " [-0.15865304 -0.03700312 -0.28040323 -0.01959608 -0.21341839]\n",
      " [-0.58757818  0.39561516  0.39413741  0.76454432  0.02237573]\n",
      " [-0.18097724 -0.24389238 -0.69160568  0.43932807 -0.49241241]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.59252326 -0.10282495  0.74307418  0.11835813]\n",
      " [-0.51189257 -0.3564966   0.31262248 -0.08025668]\n",
      " [-0.38441818 -0.11501536  0.37252813  0.98805539]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#测试initialize_parameters_deep\n",
    "print(\"==============测试initialize_parameters_deep==============\")\n",
    "layers_dims = [5,4,3]\n",
    "parameters = initialize_parameters_deep(layers_dims)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807dd44a-dd6e-49bb-b3f8-47961fa0af91",
   "metadata": {},
   "source": [
    "前向传播函数\n",
    "前向传播有以下三个步骤\n",
    "\n",
    "+ LINEAR\n",
    "+ LINEAR - >ACTIVATION，其中激活函数将会使用ReLU或Sigmoid。\n",
    "+ [LINEAR - > RELU] ×（L-1） - > LINEAR - > SIGMOID（整个模型）\n",
    "线性正向传播模块（向量化所有示例）使用公式(3)进行计算：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852b40d-2291-45b6-ac63-308e5e74ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A,W,b):\n",
    "    \"\"\"\n",
    "    实现前向传播的线性部分。\n",
    "\n",
    "    参数：\n",
    "        A - 来自上一层（或输入数据）的激活，维度为(上一层的节点数量，示例的数量）\n",
    "        W - 权重矩阵，numpy数组，维度为（当前图层的节点数量，前一图层的节点数量）\n",
    "        b - 偏向量，numpy向量，维度为（当前图层节点数量，1）\n",
    "\n",
    "    返回：\n",
    "         Z - 激活功能的输入，也称为预激活参数\n",
    "         cache - 一个包含“A”，“W”和“b”的字典，存储这些变量以有效地计算后向传递\n",
    "    \"\"\"\n",
    "    Z = np.dot(W,A) + b\n",
    "    assert(Z.shape == (W.shape[0],A.shape[1]))\n",
    "    cache = (A,W,b)\n",
    "     \n",
    "    return Z,cache\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
