# BCLNet

> 忽视这些上下文之间共享的精确信息可能会导致错误信息的放大，这会对我们的任务产生负面影响吗？

> 我们采用现有的 Order-Aware（OA）区块作为捕获本地共识的模块，并设计了一个与其并行运行的新型双边共识挖掘注意力（BCMA）区块，作为捕获全球共识的模块。
>
> BCMA 块不仅建立了全局依赖关系，而且还突出显示了局部信息，类似于人类中心视觉和周边视觉执行的匹配过程。这种局部上下文的嵌入是通过在查询、键和值特征空间中分别采用 k 最近邻 （KNN） 搜索来寻找一致的邻居来实现的。随后，我们将学习到的 OA 区块本地共识和 BCMA 区块的全局共识在通道维度上串联起来，并通过几个额外的 ResNet 区块促进它们的交互，从而形成更可靠的双边共识。如图1（d）-（f）所示，通过获取双边共识，我们的网络在对应剪枝任务中表现出显著的表现。

## 贡献

- 提出了一种新的共识学习策略，用于双视图对应剪枝任务。与以往的渐进式学习策略相反，我们**同时学习**本地和全球共识，并通过建立它们之间的相互依赖关系来获得双边共识。据我们所知，这是首次利用双边共识来处理双视图对应修剪任务。
- 我们提出了一个简单而有效的BCMA模块作为双边共识中的全局共识学习模块，以及一个BCR模块来纠正双边共识。通过学习和重新校准的过程，我们的网络能够处理复杂的匹配场景。
- 我们开发了一种有效的 BCLNet 用于对应剪枝任务。大量的实验证明了我们提出的BCLNet在对应分类任务和相机位姿估计任务上的有效性。值得注意的是，BCLNet在未知的室外数据集上比第二优方法获得了3.98%的mAP5◦增益，并且明显加快了模型训练速度。

## 模块

### BCMA Block

为了达成双边共识，必须首先以地方和全球共识为榜样。现有的 Order-Aware 区块在提取本地共识方面表现出了值得称赞的准确性。因此，必须设计一个额外的模块来捕获全球共识信息。自我注意力机制在建立全球依赖关系方面的力量给我们灌输了乐观情绪。因此，我们设计了一个独特且轻量级的双边共识挖掘注意力（BCMA）区块。更重要的是，BCMA块认识到本地信息在对应剪枝任务中的重要性，在获得全球共识之前嵌入了本地上下文

### Local Context Embedding

与传统的自注意力（Vaswani 等人，2017 年）相比，BCMA 计算跨通道的相似性分数，而不是在空间维度上计算相似性分数，这赋予了它线性复杂性，同时隐式编码全局上下文。我们还引入了环形卷积（Zhao et al. 2021）来突出局部上下文，然后再获得全局注意力图。

获得

$X_{local}=conv(softmax(q@k.T*temp)@v)+X$

### Bilateral Consensus Recalibrate Block

我们发现，在双边共识趋同后，内在特征空间中具有更高的一致性。然而，在面对一些具有挑战性的场景时，简单地通过交互作学习的特征表示是不足的。在执行对应修剪时，它仍然容易受到特征不准确的影响。

解决了它忽略了包含对我们的任务至关重要的运动一致性的重要局部环境。
$$
X_{global} = Conv1 (Conv2 (AVG(X)))
$$

$$
X_{out} = Sigmod (X_{local} + X_{global}) X
$$

更重要的是，为了在重新校准后有效地管理双边共识特征，我们还在末尾添加了三个 Resnet 块以充分处理这些特征。