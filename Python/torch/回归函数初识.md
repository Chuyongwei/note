### 创建数据集

```py
import numpy as np
import torch
from sklearn.datasets import make_regression
import matplotlib.pyplot as plt
import matplotlib
import random

# matplotlib.use("TkAgg")
# %%
def create_dataset():
    x,y,coef = make_regression(n_samples=100,
                               n_features = 1,
                               noise =10,
                               coef=True,
                               bias = 14.5,
                               random_state=0)
    
    x = torch.tensor(x)
    y = torch.tensor(y)
    return x,y
    
def data_loader(x,y,batch_size):
    # 
    data_len = len(y)
    data_index = list(range(data_len))

    random.shuffle(data_index)

    batch_number = data_len

    for idx in range(batch_number):
        start = idx + batch_size
        end = start + batch_size

        batch_train_x = x[start:end]
        batch_train_y = y[start:end]

        yield batch_train_x,batch_train_y

def test01():

    x,y = create_dataset()
    plt.scatter(x,y)
    plt.show()

    for x,y in data_loader(x,y,batch_size=10):
        print(y)

if __name__ == "__main__":
    test01()

#%%
```

### 制作模型

```python
w = torch.tensor(0.1,device=device,requires_grad = True,dtype = torch.float64)
b = torch.tensor(0.0,device=device,requires_grad = True,dtype = torch.float64)

def linear_regression(x):
    return w*x+b

def square_loss(y_pred,y_true):
    return (y_pred-y_true) **2


def square_loss(y_pred,y_true):
    return(y_pred-y_true)**2


def sgd(lr=1e-2):
    w.data = w.data - lr*w.grad.data /16
    b.data = b.data -lr*w.grad.data / 16

```

### 训练数据

```py

def train():

    x,y,coef = create_dataset()
    epochs = 100
    learning_rate = 1e-2

    epoch_loss = []
    total_loss = 0.0
    train_samples = 0


    for _ in range(epochs):
        for train_x,train_y in data_loader(x,y,batch_size=16):

            y_pred = linear_regression(train_x)

            # print(y_pred.shape)
            # print(train_y.shape)

            loss = square_loss(y_pred,train_y.reshape(-1,1)).sum()
            total_loss += loss.item()
            train_samples += len(train_y)

            if w.grad is not None:
                w.grad.data.zero_()

            if b.grad is not None:
                b.grad.data.zero_()

            loss.backward()

            sgd(learning_rate)
            print("loss :%.10f"%(total_loss/train_samples))

        epoch_loss.append(total_loss/train_samples)

    # 绘制数据集散点图
    
    plt.scatter(x,y)

    x = torch.linspace(x.min(),x.max(),1000)
    y1 = torch.tensor([v*w+14.5 for v in x],device=device)
    y2 = torch.tensor([v*coef+14.5 for v in x],device=device)

    plt.plot(x,y1,label = "训练")
    plt.plot(x,y2,label = "真实")
    plt.grid()
    plt.title("损失变化曲线")
    plt.show()

```

## 使用加载器

> 数据复杂了使用继承了Dataset的类

```py
import torch 
from torch.utils.data import Dataset,DataLoader,TensorDataset


class SampleDataset(Dataset):
    def __init__(self,x,y) -> None:
        """初始化"""
        self.x = x
        self.y = y
        self.len = len(y)
        

    def __len__(self):
        return self.len
    
    def __getitem__(self,idx):
        """根据索引返回一条样本"""
        idx = min(max(idx,0),self.len-1)

        return self.x[idx],self.y[idx]


def test01():

    x = torch.randn(100,8)

    y = torch.randint(0,2,[x.size(0),])

    sample_dataset = SampleDataset(x,y)
    print(sample_dataset[0])

def test02():

    x = torch.randn(100,8)

    y = torch.randint(0,2,[x.size(0),])

    sample_dataset = SampleDataset(x,y)

    dataloader = DataLoader(sample_dataset,batch_size=4,shuffle=True)

    for x,y in dataloader:
        print(x)
        print(y)
        break

def test03():

    x = torch.randn(100,8)

    y = torch.randint(0,2,[x.size(0),])

    sample_dataset = TensorDataset(x,y)
    dataloader = DataLoader(sample_dataset,batch_size=4,shuffle=True)

    for x,y in dataloader:
        print(x)
        print(y)
        break
    # print(sample_dataset[0])

if __name__ == '__main__':
    test03()
```

