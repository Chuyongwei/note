{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch：optim\n",
    "\n",
    "经过训练的三阶多项式，可以通过最小化平方的欧几里得距离来预测y = sin(x)从-pi到pi。\n",
    "\n",
    "此实现使用来自 PyTorch 的nn包来构建网络。\n",
    "\n",
    "与其像以前那样手动更新模型的权重，不如使用optim包定义一个优化器，该优化器将为我们更新权重。 optim包定义了许多深度学习常用的优化算法，包括 SGD + 动量，RMSProp，Adam 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 8499.17578125\n",
      "199 5169.185546875\n",
      "299 3168.580078125\n",
      "399 1973.0919189453125\n",
      "499 1324.2686767578125\n",
      "599 997.6962280273438\n",
      "699 802.49169921875\n",
      "799 644.739990234375\n",
      "899 507.01116943359375\n",
      "999 387.9773254394531\n",
      "1099 287.1012878417969\n",
      "1199 203.776611328125\n",
      "1299 137.2113800048828\n",
      "1399 86.50901794433594\n",
      "1499 50.499271392822266\n",
      "1599 27.508129119873047\n",
      "1699 15.100403785705566\n",
      "1799 10.15505313873291\n",
      "1899 9.007266998291016\n",
      "1999 8.906963348388672\n",
      "Result: y = 1.0116960424966237e-07 + 0.8553435802459717 x + 1.317946498602396e-07 x^2 + -0.09256772696971893 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Prepare the input tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use RMSprop; the optim package contains many other\n",
    "# optimization algorithms. The first argument to the RMSprop constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytestenv24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
